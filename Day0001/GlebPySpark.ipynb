{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ['SPARK_HOME'] = '/home/gleb/spark'\n",
    "SPARK_HOME = os.environ.get('SPARK_HOME', None)\n",
    "sys.path.insert(0, SPARK_HOME+ \"/python\")\n",
    "sys.path.insert(0, os.path.join(SPARK_HOME, 'python/lib/py4j-0.10.3-src.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.0.2\n",
      "      /_/\n",
      "\n",
      "Using Python version 3.5.2 (default, Jul  2 2016 17:53:06)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "exec(open('/home/gleb/spark/python/pyspark/shell.py').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gzip: t10k-images-idx3-ubyte already exists;\tnot overwritten\n",
      "gzip: t10k-labels-idx1-ubyte already exists;\tnot overwritten\n",
      "gzip: train-images-idx3-ubyte already exists;\tnot overwritten\n",
      "gzip: train-labels-idx1-ubyte already exists;\tnot overwritten\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "mkdir -p mnist && {\n",
    "    cd mnist;\n",
    "    wget -q -nc http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz &&\n",
    "    wget -q -nc http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz &&\n",
    "    wget -q -nc http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz &&\n",
    "    wget -q -nc http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz &&\n",
    "    gunzip *.gz\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, struct\n",
    "from array import array as pyarray\n",
    "from numpy import append, array, int8, uint8, zeros\n",
    "import numpy as np\n",
    "def load_mnist(dataset=\"training\", digits=np.arange(10), path=\".\"):\n",
    "    \"\"\"\n",
    "    Loads MNIST files into 3D numpy arrays\n",
    "\n",
    "    Adapted from: http://abel.ee.ucla.edu/cvxopt/_downloads/mnist.py\n",
    "    \"\"\"\n",
    "\n",
    "    if dataset == \"training\":\n",
    "        fname_img = os.path.join(path, 'train-images-idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 'train-labels-idx1-ubyte')\n",
    "    elif dataset == \"testing\":\n",
    "        fname_img = os.path.join(path, 't10k-images-idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 't10k-labels-idx1-ubyte')\n",
    "    else:\n",
    "        raise ValueError(\"dataset must be 'testing' or 'training'\")\n",
    "\n",
    "    flbl = open(fname_lbl, 'rb')\n",
    "    magic_nr, size = struct.unpack(\">II\", flbl.read(8))\n",
    "    lbl = pyarray(\"b\", flbl.read())\n",
    "    flbl.close()\n",
    "\n",
    "    fimg = open(fname_img, 'rb')\n",
    "    magic_nr, size, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
    "    img = pyarray(\"B\", fimg.read())\n",
    "    fimg.close()\n",
    "\n",
    "    ind = [ k for k in range(size) if lbl[k] in digits ]\n",
    "    N = len(ind)\n",
    "\n",
    "    images = zeros((N, rows, cols), dtype=uint8)\n",
    "    labels = zeros((N, 1), dtype=int8)\n",
    "    for i in range(len(ind)):\n",
    "        images[i] = array(img[ ind[i]*rows*cols : (ind[i]+1)*rows*cols ]).reshape((rows, cols))\n",
    "        labels[i] = lbl[ind[i]]\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = load_mnist(dataset='training', path='mnist/')\n",
    "X = X.reshape(-1, 1, 28, 28)\n",
    "\n",
    "X_test, y_test = load_mnist(dataset='testing', path='mnist/')\n",
    "X_test = X_test.reshape(-1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rdd = sc.parallelize(\n",
    "    (i, y[i], X[i].ravel().copy())\n",
    "    for i in range(X.shape[0])\n",
    ").repartition(64).persist()\n",
    "\n",
    "X_test_rdd = sc.parallelize(\n",
    "    (i, y_test[i], X_test[i].ravel().copy())\n",
    "    for i in range(X_test.shape[0])\n",
    ").repartition(64).persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(object):\n",
    "    def __init__(self):\n",
    "        self.W = np.random.uniform(-1,1, size = (28*28,10)) #10 classes, 28*28 features\n",
    "        self.b = np.random.uniform(-1,1, size = (10,))\n",
    "        self.I = np.eye(10,10)\n",
    "        \n",
    "    def predict(self,x): \n",
    "        dot = np.dot(x,self.W)+self.b\n",
    "        x_max = np.max(dot)\n",
    "        exps = np.exp(dot-x_max)\n",
    "        return exps/np.sum(exps)\n",
    "    \n",
    "    def next_iter(self,X,batch_size, learning_rate = 0.9):\n",
    "        mini_batch = X.sample(withReplacement=False, fraction = batch_size).cache()\n",
    "        N = 1/(batch_size*60000)\n",
    "        #index,target,features\n",
    "        W_grad = mini_batch.map(lambda x: N*np.outer(x[2], self.I[x[1]]-self.predict(x[2]))).reduce(lambda a,b: a+b)\n",
    "        b_grad = mini_batch.flatMap(lambda x: N*(self.I[x[1]]-self.predict(x[2]))).reduce(lambda a,b: a+b)\n",
    "        self.W += learning_rate*W_grad\n",
    "        self.b += learning_rate*b_grad\n",
    "        \n",
    "    def get_accuracy(self, X):\n",
    "        predicted = X.flatMap(lambda x: np.argmax(self.predict(x[2])) == x[1]).collect()\n",
    "        return sum(predicted)/X.count()\n",
    "    \n",
    "    def fit(self, X, batch_size = 0.3, learning_rate=0.9, num_iter=100):\n",
    "        for i in range(num_iter):\n",
    "            print(i)\n",
    "            self.next_iter(X,batch_size,learning_rate)\n",
    "            #print('Iteration {0} -----> {1: .2f}% accuracy'.format(i,get_accuracy(X_test_rdd)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = LogisticRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "l.fit(X_train_rdd,num_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84740000000000004"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.get_accuracy(X_test_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
